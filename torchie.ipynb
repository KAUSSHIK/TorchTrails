{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch Basics Notebook\n",
    "\n",
    "## Introduction\n",
    "Welcome to the PyTorch Basics Notebook! In this notebook, we will explore the fundamental concepts and functionalities of PyTorch, a popular deep learning framework. PyTorch provides a flexible and intuitive way to build and train neural networks.\n",
    "\n",
    "## Table of Contents\n",
    "1. Tensor Basics\n",
    "2. Tensor Operations\n",
    "3. CUDA Tensors\n",
    "4. Autograd and Gradients\n",
    "5. Dataset and DataLoader\n",
    "6. Neural Networks\n",
    "7. Loss Functions and Optimizers\n",
    "8. Training Loop\n",
    "9. Model Evaluation\n",
    "10. Saving and Loading Models\n",
    "11. Transfer Learning\n",
    "12. Data Augmentation\n",
    "13. Distributed Training\n",
    "\n",
    "## 1. Tensor Basics\n",
    "PyTorch is built around tensors, which are similar to NumPy arrays but can also be used on GPUs for accelerated computing. Let's start by creating a tensor and exploring its properties.\n",
    "\n",
    "### ELI5: Tensors\n",
    "Imagine tensors as containers that can hold numbers. Just like you can have boxes of different sizes and shapes to store your toys, tensors can have different dimensions and sizes to store numbers. Tensors are the building blocks of PyTorch, and we use them to represent and manipulate data in our programs.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76ee61bd80515f68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5153a067dc29b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Tensor Operations\n",
    "PyTorch provides a wide range of tensor operations that allow us to perform mathematical computations on tensors. Let's explore some common tensor operations.\n",
    "## ELI5: Tensor Operations\n",
    "Just like you can add, subtract, or multiply numbers, you can do similar operations on tensors. Tensor operations help us manipulate and transform the data stored in tensors. We can perform element-wise operations, matrix multiplication, and more."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db031bdb0cfc4883"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensor = torch.ones(3, 4)\n",
    "print(tensor + 5)\n",
    "print(tensor * 2)\n",
    "print(torch.matmul(tensor, tensor.T))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8377ffa2e204181"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. CUDA Tensors\n",
    "PyTorch allows us to leverage the power of NVIDIA GPUs to accelerate computations. By moving tensors to CUDA-enabled devices, we can perform operations much faster.\n",
    "## ELI5: CUDA Tensors\n",
    "Imagine you have a superhero friend named CUDA who can help you do your tasks faster. When you give your toys (tensors) to CUDA, it can play with them and finish tasks quickly. In PyTorch, we can move our tensors to CUDA devices (like GPUs) to make our programs run faster."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f86d9ffbda37e99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    tensor = tensor.to(device)\n",
    "    print(tensor)\n",
    "else:\n",
    "    print(\"CUDA not available\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed52b862d39dd04f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Autograd and Gradients\n",
    "PyTorch's autograd package provides automatic differentiation capabilities, which are essential for training neural networks. Let's see how we can use autograd to compute gradients.\n",
    "\n",
    "### ELI5: Autograd and Gradients\n",
    "Imagine you are hiking on a mountain, and you want to find the steepest path to the top. Gradients are like arrows that point in the direction of the steepest climb. In PyTorch, autograd helps us find these arrows (gradients) automatically, making it easier to train our models and reach the top of the mountain (optimal solution).\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff6347f304cc6f75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., 2., 3.], [4., 5., 6.]], requires_grad=True)\n",
    "y = x ** 2\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "print(x.grad)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b697507cf291b9cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Dataset and DataLoader\n",
    "PyTorch provides the Dataset and DataLoader classes to efficiently load and preprocess data for training models. Let's create a custom dataset and use a DataLoader to iterate over it.\n",
    "## ELI5: Dataset and DataLoader\n",
    "Imagine you have a toy collection, and you want to play with a few toys at a time. A Dataset is like your entire toy collection, and a DataLoader is like a helper who brings you a few toys to play with in each turn. This way, you can enjoy your toys in smaller groups rather than playing with all of them at once."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddd34b6da9e760ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "data = torch.randn(100, 10)\n",
    "labels = torch.randint(0, 5, (100,))\n",
    "dataset = CustomDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76e5642125be39bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Neural Networks\n",
    "PyTorch provides a module called nn to define and build neural networks. Let's create a simple neural network using the nn.Module class.\n",
    "## ELI5: Neural Networks\n",
    "Imagine a neural network as a machine that can learn to recognize patterns. It has different parts (layers) that work together to understand the input and make predictions. We can teach the machine by showing it many examples and adjusting its parts until it becomes really good at recognizing patterns."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bda80270e158b541"
  },
  {
   "cell_type": "markdown",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92e90b9026e57e1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Loss Functions and Optimizers\n",
    "Loss functions measure how well our model is performing, and optimizers help adjust the model's parameters to minimize the loss. PyTorch provides various loss functions and optimization algorithms.\n",
    "## ELI5: Loss Functions and Optimizers\n",
    "Imagine you are playing a game where you need to guess a number. The loss function is like a score that tells you how far your guess is from the correct number. The optimizer is like a guide who helps you adjust your guesses based on the score, so you can get closer to the correct number with each attempt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58c567bca0a14197"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a21959936b9b63ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Training Loop\n",
    "The training loop is where we iterate over the dataset, perform forward and backward passes, and update the model's parameters. Let's implement a basic training loop.\n",
    "## ELI5: Training Loop\n",
    "Imagine you are teaching a robot to perform a task. The training loop is like repeatedly showing the robot how to do the task and letting it practice. Each time the robot practices, it learns from its mistakes and gets better at the task. We keep repeating this process until the robot becomes really good at performing the task."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff76112579f9971a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} loss: {running_loss / len(dataloader):.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3635344a08d8b80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Model Evaluation\n",
    "After training our model, we need to evaluate its performance on unseen data. Let's evaluate our model on the test dataset.\n",
    "## ELI5: Model Evaluation\n",
    "Imagine you have taught a friend how to solve puzzles. To see how well your friend has learned, you give them new puzzles they haven't seen before and check how many they can solve correctly. This is like evaluating a trained model on a test dataset to see how well it performs on new, unseen data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7afdbb90fcc4e01c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader:\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy: {100 * correct / total:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cac595c315bf3c91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10. Saving and Loading Models\n",
    "We often need to save trained models for later use or share them with others. PyTorch allows us to save and load model state dictionaries.\n",
    "## ELI5: Saving and Loading Models\n",
    "Imagine you have built a really cool LEGO model, and you want to show it to your friends later. You can take apart the model and put the pieces in a special box (save the model) and then rebuild it later (load the model) to show your friends. This way, you don't have to build the model from scratch every time you want to show it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d29f244d0a6c386"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"model.pth\")\n",
    "loaded_net = Net()\n",
    "loaded_net.load_state_dict(torch.load(\"model.pth\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d4112370ec45bb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11. Transfer Learning\n",
    "Transfer learning allows us to use pre-trained models and fine-tune them for our specific tasks. PyTorch provides many pre-trained models that we can use as a starting point.\n",
    "## ELI5: Transfer Learning\n",
    "Imagine you want to learn to play a new musical instrument, but you already know how to play the piano. Instead of starting from scratch, you can use your existing knowledge of music and apply it to learn the new instrument faster. This is like transfer learning, where we use a pre-trained model that has already learned general features and adapt it to our specific task, making the learning process faster and easier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ffec3c59ccbcbf8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa3ba05720eadc15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 12. Data Augmentation\n",
    "Data augmentation is a technique used to artificially increase the size and diversity of the training dataset by applying random transformations to the input data. PyTorch provides various transforms in the torchvision package.\n",
    "## ELI5: Data Augmentation\n",
    "Imagine you have a few toy cars, but you want to have more variety in your collection. You can use your imagination to create new cars by painting them different colors, adding stickers, or changing their wheels. This is like data augmentation, where we take existing data and apply different transformations to create new, varied examples for our model to learn from."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d05f42d8e24717d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "701097baa0807c94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 13. Distributed Training\n",
    "Distributed training allows us to train models on multiple GPUs or machines to accelerate the training process. PyTorch provides built-in support for distributed training.\n",
    "## ELI5: Distributed Training\n",
    "Imagine you and your friends want to build a big LEGO model together. Instead of building it alone, you can divide the work among your friends, and each person can work on a different part of the model simultaneously. This way, you can build the model much faster than if you were working alone. Distributed training is similar, where we split the training process across multiple GPUs or machines to make it faster and more efficient."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "764d1ba589f0c939"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs for training\")\n",
    "    net = nn.DataParallel(net)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e84a94678f4fb2b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "Congratulations! You(I) have completed the PyTorch Basics Notebook. You have learned about tensors, tensor operations, CUDA tensors, autograd, datasets, neural networks, training, evaluation, saving and loading models, transfer learning, data augmentation, and distributed training. PyTorch provides a powerful and flexible framework for building and training deep learning models. Keep exploring and building amazing projects with PyTorch!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df53394ed4306f0a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
